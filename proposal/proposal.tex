\documentclass[conference]{IEEEtran}

% Packages

\usepackage{cite}
\usepackage{listings}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{parskip}
\setlength{\parskip}{1em}
\usepackage[bottom]{footmisc}
\usepackage{url}
\begin{document}
\input{commands}

\title{Two Differing Approaches to Survival Analysis of Open Source Python Projects}

\author{\IEEEauthorblockN{Derek Robinson, Keanelek Enns, Neha Koulecar, Manish Sihag}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{University of Victoria}\\
Victoria, Canada \\
\{drobinson, keanelekenns, nehakoulecar, manishsihag\}@uvic.ca}
}

\maketitle

\section{Motivation}

The developers of Open Source Software (OSS) projects are often part of decentralized and geographically distributed teams of volunteers. As these developers volunteer their free time to build free software for the masses, they likely want to ensure the projects they work on do not become inactive. If OSS developers are aware of key attributes that are associated with long-lasting projects, they can make informed assessments of a given project before devoting their time to it or they can strive to make their own projects exhibit those attributes. Understanding which attributes of an OSS project lead to its longevity is what motivated Ali \emph{et al.} to apply survival analysis techniques commonly found in biostatistics to study the probability of survival for popular OSS Python projects \cite{ali2020cheating}. Ali \emph{et al.} specifically studied the effect that publishing major releases, the use of multiple repositories, the type of version control system (VCS), and the size of the volunteer team had on the survival of OSS Python projects. We resonate with Ali \emph{et al.'s} motivation and would like to replicate \cite{ali2020cheating} in order to determine if there are any shortcomings in their analysis. In addition to the replication study, we also plan on applying a Bayesian approach to survival analysis as outlined in \cite{kelter2020bayesian}. The Bayesian portion of our paper is motivated by comparing the findings of the two different approaches to survival analysis.

Thus, the research questions we plan on answering are as follows:

\begin{enumerate}
    \item \textbf{How do major releases, the use of multiple repositories, the type of VCS, and the size of the volunteer team affect the survival of an OSS Python project?}\\
    \item \textbf{How do the findings of frequentist survival analysis differ from Bayesian survival analysis?}
\end{enumerate}

\section{Research Strategies}

\subsection{Data}

Performing survival analysis of OSS projects requires a dataset that records the repositories for projects on common VCSs, including a history of all commits (revisions from here on out) and major releases (revisions of note, often with a specific name and release date) \cite{ali2020cheating}. The \emph{popular-3k-python} subset of the Software Heritage graph dataset \cite{pietri2019software} is what will be used in both our replication study and Bayesian survival analysis study. This dataset contains information on roughly 3000 popular Python projects hosted on Gitlab, GitHub, Debian, and PyPI between 2005 and 2018. Our current plan is to host the dataset on an SQL server, specifically, a postgres SQL server as the Software Heritage Graph offers a tutorial on how to do this \cite{SQLdataset}.
 
\subsection{Methods}

Survival analysis is a set of methods used to determine how long an entity will live (or the time to a given event) and is most often used in the medical field. For example, survival analysis techniques can determine the probability that a patient will survive when given a certain treatment. The methods of survival analysis we will use in the replication study are the Kaplan-Meier (K-M) survival estimator and the Cox Proportional-Hazards model. For the comparison between traditional survival analysis and Bayesian survival analysis, we will be applying the methods found in \cite{kelter2020bayesian}. We plan on using the R programming language to perform both of our analysis methods, specifically the R package \texttt{survival} for the replication portion of the study and the R to Stan interface \texttt{rstan} for the Bayesian analysis portion of the study.

\subsubsection{Kaplan-Meier Estimator and Cox Proportional-Hazards Model}

When applying survival analysis techniques, one very important aspect is censoring. If our event of interest is the inactivity of a project and this event does not occur during the period our data covers, then the time to event is said to be censored. Ali \emph{et al.} decided that the period that they would analyze was 165 months long, starting in 2005 and ending in January 2018. They also deemed that any project ``that has revisions beyond the January 2018 cutoff date is surely active and is deemed censored.'' \cite{ali2020cheating} The K-M estimator is used to estimate the survival function. In our use case, the K-M estimator will estimate the probability that the duration of a project is longer than time $t$. The other analysis we will be performing is fitting a Cox Proportional-Hazards model. The Cox Proportional-Hazards model is a regression model that will allow us to investigate the association between the survival of a project and its key attributes.

\subsubsection{Bayesian Survival Analysis}

For the second portion of our study, we will be applying the same methods as found in the section titled \emph{A detailed example} of \cite{kelter2020bayesian}. More specifically, we will be using a parametric exponential model that assumes the survival times of a project $y = (y_1, y_2, \dots, y_n)$ are exponentially distributed with parameter $\lambda$. We will then use our model to visualize the posterior survival functions for the following four project attributes: major releases, VCS of the project, use of multiple VCSs, and team size.

\section{Expected Results}

We expect that our replication of \cite{ali2020cheating} will yield similar results to the original analysis. Additionally, as the survival analysis techniques outlined in \cite{ali2020cheating} and the Bayesian approach to survival analysis outlined in \cite{kelter2020bayesian} are two different approaches to the same goal, we suspect that the results of both will be comparable.

\section{Limitations}

Both the data we analyze and the methods of analysis have their own respective limitations, as such, this section will cover each individually.

\subsection{Limitations of the Methods}

Survival analysis methods such as the K-M estimator and the Cox Proportional-Hazards model have limitations of their own. When applying the K-M estimator, it is common to use a log-rank test to test the significance between the two groups which are being compared. The log-rank test only tells you whether or not the probability of survival is statistically significant between the two groups and is not able to provide any information about the size of the difference between the two groups \cite{stel2011kaplan}. Additionally, the K-M estimator does not account for confounding factors \cite{stel2011kaplan}. In more traditional uses of the K-M estimator, an example of a confounding factor could be the age of the study participants. However, in our use case, we have not been unable to identify any confounding factors. The Cox Proportional-Hazards model comes with is used with the assumption that over the period of observation the hazards within each group are proportional \cite{stel2011cox}. If the assumption that the hazards within each group are proportional is not true, then the Cox Proportional-Hazards model will lead to incorrect estimates of the survival probability \cite{stel2011cox}.

The Bayesian approach to survival analysis comes with its own limitations as well. As pointed out by Renganathan, Bayesian survival analysis can be subjective as the analyst places their own bias into the model when selecting the prior distributions \cite{renganathan2016overview}. In order to mitigate this bias, prior selection requires both epistemological and ontological reasoning.

\subsection{Limitations of the Data}

The data we are analyzing has been aggregated from multiple version control systems across the web over a long period. As such, the data set is not fully reproducible, as pointed out by the original authors of the Software Heritage Graph \cite{pietri2019software}. Additionally, we cannot ensure that the data we are analyzing is a full history of the respective repositories. The lack of certainty about the full history is because the repository admin can modify the history of revisions to suit their liking.

\bibliographystyle{IEEEtran}
\bibliography{../refs/refs.bib}
\end{document}